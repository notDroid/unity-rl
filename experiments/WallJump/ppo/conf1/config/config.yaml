env:
  name: WallJump
  observation:
    type: vector
    dim: 444
  action:
    type: discrete
    dim: 54
  info:
    batch_dims: 1
    n_envs: 24
  params:
    time_scale: 10
    path: envs/WallJump-linux/WallJump.x86_64
repo_id: notnotDroid/unity-rl
conf_name: conf1
run_name: run2
algo:
  name: ppo
  _target_: runners.ppo.PPORunner
  params:
    epsilon: 0.2
    entropy_coef: 0.01
    gamma: 0.99
trainer:
  _target_: rlkit.templates.PPOBasic
  params:
    generations: 5000
    generation_size: 96000
    slice_len: 200
    n_slices: 256
    epochs: 10
    minibatch_size: 1024
    workers: 10
    env_batch_dim: ${env.info.batch_dims}
    kl_soft_clip: 0.02
    early_stop_threshold: 32
    kl_hard_clip: 0.05
model:
  _target_: rlkit.models.MLP
  params:
    in_features: ${env.observation.dim}
    out_features: ${env.action.dim}
    n_blocks: 1
    hidden_dim: 128
optimizer:
  _target_: torch.optim.Adam
  params:
    lr: 1.0e-07
dir: experiments/${env.name}/${algo.name}/${conf_name}
model_path: ${dir}/models/${run_name}.pt
results_path: ${dir}/results/${run_name}.png
logger:
  _target_: rlkit.utils.HFTBLogger
  log_dir: ${dir}/logs/${run_name}
  repo_id: ${repo_id}
  repo_subfolder: ${dir}/logs/${run_name}
checkpointer:
  _target_: rlkit.utils.HFCheckpointer
  ckpt_path: ${dir}/ckpts
  name: ${run_name}
  repo_id: ${repo_id}
lr_scheduler:
  _target_: rlkit.utils.CosineWithLinearWarmupSchedule
  warmup_epochs: 5
  initial_lr: 1.0e-07
  max_lr: 0.0001
verbose: true
continue_: true
hf_sync_interval: 500
