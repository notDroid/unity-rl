{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3DBallEnv Reinforcement Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "### Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "# Model\n",
    "from ffn import MLP\n",
    "\n",
    "### Torch RL\n",
    "# Env\n",
    "from torchrl.envs.libs import UnityMLAgentsEnv\n",
    "from torchrl.envs.utils import MarlGroupMapType, step_mdp, check_env_specs\n",
    "\n",
    "from torchrl.envs import Transform, TransformedEnv, Compose, Stack, RenameTransform, ExcludeTransform\n",
    "\n",
    "\n",
    "# Modules\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torchrl.modules import ProbabilisticActor, TanhNormal\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Data Collection\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import LazyTensorStorage, ReplayBuffer, Composite\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "\n",
    "# Loss\n",
    "from torchrl.objectives import ClipPPOLoss, ValueEstimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create Torch Env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unity_env(graphics=False):\n",
    "    try:\n",
    "        env.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    env = TransformedEnv(UnityMLAgentsEnv(\n",
    "        file_name=\"../../../envs/3DBall\", worker_id=np.random.randint(10000), no_graphics=(not graphics),\n",
    "    ))\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agents not Batched**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.063 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.292458 ms\n",
      "Registered Communicator in Agent.\n",
      "ERROR: Shader UI/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "Thread 0x16f1f3000 may have been prematurely finalized\n",
      "Setting up 7 worker threads for Enlighten.\n",
      "Thread 0x16dcdf000 may have been prematurely finalized\n",
      "Memory Statistics:\n",
      "[ALLOC_TEMP_TLS] TLS Allocator\n",
      "  StackAllocators : \n",
      "    [ALLOC_TEMP_MAIN]\n",
      "      Peak usage frame count: [2.0 MB-4.0 MB]: 1 frames\n",
      "      Initial Block Size 4.0 MB\n",
      "      Current Block Size 4.0 MB\n",
      "      Peak Allocated Bytes 2.1 MB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 4]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.PreloadManager]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 78.9 KB\n",
      "      Overflow Count 4\n",
      "    [ALLOC_TEMP_Background Job.worker 3]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 11]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 7]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 6]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 11]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 12]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 2]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 9]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 0]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 4]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 5]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 8]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 10]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 1]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_EnlightenWorker] x 7\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 1]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.5 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 3]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 5]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 12]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_AssetGarbageCollectorHelper] x 13\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 13]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 15]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 2]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.7 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 10]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 7]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_OSX HID Input]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 9]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 0]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 6]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 8]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 14]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.AsyncRead]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 128 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_BatchDeleteObjects]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "[ALLOC_DEFAULT] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 29\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_DEFAULT_MAIN]\n",
      "      Peak usage frame count: [16.0 MB-32.0 MB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 28.9 MB\n",
      "      Peak Large allocation bytes 16.0 MB\n",
      "    [ALLOC_DEFAULT_THREAD]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 0.8 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TEMP_JOB_1_FRAME]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_2_FRAMES]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 0\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_4_FRAMES (JobTemp)]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_ASYNC (Background)]\n",
      "  Initial Block Size 1.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_GFX] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_GFX_MAIN]\n",
      "      Peak usage frame count: [64.0 KB-128.0 KB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 69.7 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_GFX_THREAD]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 32.2 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_CACHEOBJECTS] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_CACHEOBJECTS_MAIN]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 1 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 0.7 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_CACHEOBJECTS_THREAD]\n",
      "      Peak usage frame count: [2.0 MB-4.0 MB]: 1 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 2.5 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TYPETREE] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_TYPETREE_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 1 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 112 B\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_TYPETREE_THREAD]\n",
      "      Peak usage frame count: [1.0 KB-2.0 KB]: 1 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.9 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "ERROR: Shader UI/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "\u001b[92m2025-09-22 18:02:13,775 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n",
      "action_spec: Composite(\n",
      "    group_0: Composite(\n",
      "        agent_0: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_1: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_2: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_3: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_4: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_5: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_6: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_7: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_8: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_9: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_10: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_11: Composite(\n",
      "            continuous_action: BoundedContinuous(\n",
      "                shape=torch.Size([2]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        device=None,\n",
      "        shape=torch.Size([]),\n",
      "        data_cls=None),\n",
      "    device=None,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "reward_spec: Composite(\n",
      "    group_0: Composite(\n",
      "        agent_0: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_1: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_2: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_3: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_4: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_5: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_6: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_7: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_8: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_9: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_10: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_11: Composite(\n",
      "            reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            group_reward: UnboundedContinuous(\n",
      "                shape=torch.Size([1]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        device=None,\n",
      "        shape=torch.Size([]),\n",
      "        data_cls=None),\n",
      "    device=None,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "done_spec: Composite(\n",
      "    group_0: Composite(\n",
      "        agent_0: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_1: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_2: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_3: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_4: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_5: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_6: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_7: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_8: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_9: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_10: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_11: Composite(\n",
      "            done: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            terminated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            truncated: Categorical(\n",
      "                shape=torch.Size([1]),\n",
      "                space=CategoricalBox(n=2),\n",
      "                device=cpu,\n",
      "                dtype=torch.bool,\n",
      "                domain=discrete),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        device=None,\n",
      "        shape=torch.Size([]),\n",
      "        data_cls=None),\n",
      "    device=None,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "observation_spec: Composite(\n",
      "    group_0: Composite(\n",
      "        agent_0: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_1: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_2: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_3: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_4: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_5: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_6: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_7: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_8: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_9: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_10: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        agent_11: Composite(\n",
      "            VectorSensor_size8: UnboundedContinuous(\n",
      "                shape=torch.Size([8]),\n",
      "                space=ContinuousBox(\n",
      "                    low=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                    high=Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "                device=cpu,\n",
      "                dtype=torch.float32,\n",
      "                domain=continuous),\n",
      "            device=None,\n",
      "            shape=torch.Size([]),\n",
      "            data_cls=None),\n",
      "        device=None,\n",
      "        shape=torch.Size([]),\n",
      "        data_cls=None),\n",
      "    device=None,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n"
     ]
    }
   ],
   "source": [
    "def print_specs(env):\n",
    "    print(\"action_spec:\", env.action_spec)\n",
    "    print(\"reward_spec:\", env.reward_spec)\n",
    "    print(\"done_spec:\", env.done_spec)\n",
    "    print(\"observation_spec:\", env.observation_spec)\n",
    "\n",
    "env = create_unity_env()\n",
    "check_env_specs(env)\n",
    "print_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_0\n",
      "12\n",
      "['agent_0', 'agent_1', 'agent_2', 'agent_3', 'agent_4', 'agent_5', 'agent_6', 'agent_7', 'agent_8', 'agent_9', 'agent_10', 'agent_11']\n"
     ]
    }
   ],
   "source": [
    "agent_root_key = env.observation_keys[0][0]\n",
    "print(agent_root_key)\n",
    "n_agents = len(env.action_spec[agent_root_key])\n",
    "print(n_agents)\n",
    "agents = list(env.action_spec[agent_root_key].keys())\n",
    "print(agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        group_0: TensorDict(\n",
       "            fields={\n",
       "                agent_0: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_10: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_11: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_1: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_2: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_3: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_4: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_5: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_6: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_7: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_8: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                agent_9: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        continuous_action: Tensor(shape=torch.Size([15, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([15]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                group_0: TensorDict(\n",
       "                    fields={\n",
       "                        agent_0: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_10: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_11: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_1: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_2: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_3: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_4: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_5: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_6: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_7: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_8: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False),\n",
       "                        agent_9: TensorDict(\n",
       "                            fields={\n",
       "                                VectorSensor_size8: Tensor(shape=torch.Size([15, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                done: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                group_reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                reward: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                terminated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                                truncated: Tensor(shape=torch.Size([15, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                            batch_size=torch.Size([15]),\n",
       "                            device=None,\n",
       "                            is_shared=False)},\n",
       "                    batch_size=torch.Size([15]),\n",
       "                    device=None,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([15]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([15]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.rollout(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Batch Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_agents(env, out_key=\"agents\"):\n",
    "    agent_root_key = env.observation_keys[0][0]\n",
    "    agents = list(env.action_spec[agent_root_key].keys())\n",
    "    \n",
    "    # Create transform\n",
    "    stack = Stack(\n",
    "        in_keys=[(agent_root_key, agent) for agent in agents], \n",
    "        out_key=(out_key,), \n",
    "        in_key_inv=(out_key,), \n",
    "        out_keys_inv=[(agent_root_key, agent) for agent in agents]\n",
    "    )\n",
    "\n",
    "    env.append_transform(stack)\n",
    "    return env\n",
    "\n",
    "def create_base_env(graphics=False):\n",
    "    env = create_unity_env(graphics)\n",
    "    env = batch_agents(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.048 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.275083 ms\n",
      "Registered Communicator in Agent.\n",
      "Thread 0x170ea3000 may have been prematurely finalized\n",
      "Setting up 7 worker threads for Enlighten.\n",
      "Thread 0x16f98f000 may have been prematurely finalized\n",
      "Thread 0x16fa1b000 may have been prematurely finalized\n",
      "Memory Statistics:\n",
      "[ALLOC_TEMP_TLS] TLS Allocator\n",
      "  StackAllocators : \n",
      "    [ALLOC_TEMP_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 16092 frames, [1.0 KB-2.0 KB]: 90 frames, [2.0 MB-4.0 MB]: 1 frames\n",
      "      Initial Block Size 4.0 MB\n",
      "      Current Block Size 4.0 MB\n",
      "      Peak Allocated Bytes 2.1 MB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 4]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.PreloadManager]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 78.9 KB\n",
      "      Overflow Count 4\n",
      "    [ALLOC_TEMP_Background Job.worker 3]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 11]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 7]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 6]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 11]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 12]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 2]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 9]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 0]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 4]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 5]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 8]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 10]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 1]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_EnlightenWorker] x 7\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 1]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.7 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 3]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 5]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 12]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_AssetGarbageCollectorHelper] x 13\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 13]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 15]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 2]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 249 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 10]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 7]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_OSX HID Input]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 9]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 0]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 6]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 8]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 14]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.AsyncRead]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 128 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_BatchDeleteObjects]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "[ALLOC_DEFAULT] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 29\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_DEFAULT_MAIN]\n",
      "      Peak usage frame count: [16.0 MB-32.0 MB]: 16183 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 28.9 MB\n",
      "      Peak Large allocation bytes 16.0 MB\n",
      "    [ALLOC_DEFAULT_THREAD]\n",
      "      Peak usage frame count: [1.0 MB-2.0 MB]: 16183 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.5 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TEMP_JOB_1_FRAME]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_2_FRAMES]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 0\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_4_FRAMES (JobTemp)]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_ASYNC (Background)]\n",
      "  Initial Block Size 1.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_GFX] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_GFX_MAIN]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 16182 frames, [64.0 KB-128.0 KB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 69.7 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_GFX_THREAD]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 16183 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 32.4 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_CACHEOBJECTS] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_CACHEOBJECTS_MAIN]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 16183 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 0.7 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_CACHEOBJECTS_THREAD]\n",
      "      Peak usage frame count: [256.0 KB-0.5 MB]: 16182 frames, [2.0 MB-4.0 MB]: 1 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 2.5 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TYPETREE] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_TYPETREE_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 16183 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 112 B\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_TYPETREE_THREAD]\n",
      "      Peak usage frame count: [1.0 KB-2.0 KB]: 16183 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.9 KB\n",
      "      Peak Large allocation bytes 0 B\n"
     ]
    }
   ],
   "source": [
    "env = create_base_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Shader UI/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "\u001b[92m2025-09-22 18:02:16,231 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n",
      "action_spec: Composite(\n",
      "    agents: Composite(\n",
      "        continuous_action: BoundedContinuous(\n",
      "            shape=torch.Size([12, 2]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([12, 2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([12, 2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=None,\n",
      "        shape=torch.Size([12]),\n",
      "        data_cls=None),\n",
      "    device=None,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "reward_spec: Composite(\n",
      "    agents: Composite(\n",
      "        reward: UnboundedContinuous(\n",
      "            shape=torch.Size([12, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([12, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([12, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        group_reward: UnboundedContinuous(\n",
      "            shape=torch.Size([12, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([12, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([12, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=None,\n",
      "        shape=torch.Size([12]),\n",
      "        data_cls=None),\n",
      "    device=None,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "done_spec: Composite(\n",
      "    agents: Composite(\n",
      "        done: Categorical(\n",
      "            shape=torch.Size([12, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        terminated: Categorical(\n",
      "            shape=torch.Size([12, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        truncated: Categorical(\n",
      "            shape=torch.Size([12, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        device=None,\n",
      "        shape=torch.Size([12]),\n",
      "        data_cls=None),\n",
      "    device=None,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "observation_spec: Composite(\n",
      "    agents: Composite(\n",
      "        VectorSensor_size8: UnboundedContinuous(\n",
      "            shape=torch.Size([12, 8]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([12, 8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([12, 8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=None,\n",
      "        shape=torch.Size([12]),\n",
      "        data_cls=None),\n",
      "    device=None,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)\n",
    "print_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                VectorSensor_size8: Tensor(shape=torch.Size([16, 12, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                continuous_action: Tensor(shape=torch.Size([16, 12, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([16, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([16, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([16, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([16, 12]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([16, 12, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([16, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        group_reward: Tensor(shape=torch.Size([16, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([16, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([16, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([16, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([16, 12]),\n",
       "                    device=None,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([16]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([16]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = env.rollout(100)\n",
    "td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Env Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.047 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.294458 ms\n",
      "Registered Communicator in Agent.\n",
      "Thread 0x16ce17000 may have been prematurely finalized\n",
      "Setting up 7 worker threads for Enlighten.\n",
      "Thread 0x16b903000 may have been prematurely finalized\n",
      "Memory Statistics:\n",
      "[ALLOC_TEMP_TLS] TLS Allocator\n",
      "  StackAllocators : \n",
      "    [ALLOC_TEMP_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 13670 frames, [1.0 KB-2.0 KB]: 76 frames, [2.0 MB-4.0 MB]: 1 frames\n",
      "      Initial Block Size 4.0 MB\n",
      "      Current Block Size 4.0 MB\n",
      "      Peak Allocated Bytes 2.1 MB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 4]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.PreloadManager]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 78.9 KB\n",
      "      Overflow Count 4\n",
      "    [ALLOC_TEMP_Background Job.worker 3]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 11]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 7]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 6]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 11]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 12]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 2]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 9]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 0]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 4]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 5]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 8]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 10]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 1]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_EnlightenWorker] x 7\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 1]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.7 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 3]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 5]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 12]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_AssetGarbageCollectorHelper] x 13\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 13]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 15]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 2]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 10]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 7]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_OSX HID Input]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 9]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 0]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 6]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 8]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 14]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.AsyncRead]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 128 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_BatchDeleteObjects]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "[ALLOC_DEFAULT] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 29\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_DEFAULT_MAIN]\n",
      "      Peak usage frame count: [16.0 MB-32.0 MB]: 13747 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 28.9 MB\n",
      "      Peak Large allocation bytes 16.0 MB\n",
      "    [ALLOC_DEFAULT_THREAD]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 1414 frames, [1.0 MB-2.0 MB]: 12333 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.2 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TEMP_JOB_1_FRAME]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_2_FRAMES]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 0\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_4_FRAMES (JobTemp)]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_ASYNC (Background)]\n",
      "  Initial Block Size 1.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_GFX] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_GFX_MAIN]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 13746 frames, [64.0 KB-128.0 KB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 69.7 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_GFX_THREAD]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 13747 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 32.4 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_CACHEOBJECTS] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_CACHEOBJECTS_MAIN]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 13747 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 0.7 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_CACHEOBJECTS_THREAD]\n",
      "      Peak usage frame count: [256.0 KB-0.5 MB]: 13746 frames, [2.0 MB-4.0 MB]: 1 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 2.5 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TYPETREE] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_TYPETREE_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 13747 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 112 B\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_TYPETREE_THREAD]\n",
      "      Peak usage frame count: [1.0 KB-2.0 KB]: 13747 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.9 KB\n",
      "      Peak Large allocation bytes 0 B\n"
     ]
    }
   ],
   "source": [
    "env = create_base_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect Keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_key: VectorSensor_size8, action_key: continuous_action\n",
      "observation_shape: torch.Size([12, 8]), action_shape: torch.Size([12, 2])\n"
     ]
    }
   ],
   "source": [
    "observation_key = env.observation_keys[0][1]\n",
    "action_key = env.action_key[1]\n",
    "print(f\"observation_key: {observation_key}, action_key: {action_key}\")\n",
    "\n",
    "observation_shape = env.observation_spec[\"agents\", observation_key].shape\n",
    "action_shape = env.action_spec[\"agents\", action_key].shape\n",
    "\n",
    "print(f\"observation_shape: {observation_shape}, action_shape: {action_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect Action Space**\n",
    "\n",
    "Actions are in [-1, 1] as expected. No need for further tampering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.014681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.587857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.997469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.494984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.034970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.535219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.990092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           action\n",
       "count  312.000000\n",
       "mean     0.014681\n",
       "std      0.587857\n",
       "min     -0.997469\n",
       "25%     -0.494984\n",
       "50%      0.034970\n",
       "75%      0.535219\n",
       "max      0.990092"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = env.rollout(100)\n",
    "actions_df = pd.DataFrame({\n",
    "    \"action\": td[\"agents\", action_key].reshape(-1)\n",
    "})\n",
    "actions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: -1.0 high: 1.0\n"
     ]
    }
   ],
   "source": [
    "space = env.action_spec[\"agents\", action_key].space\n",
    "print(\"low:\", float(space.low[0, 0]), \"high:\", float(space.high[0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect Observation Space**\n",
    "\n",
    "Observation are around z score normalized. No need for further tampering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.243541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.418613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.120198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.249621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.473056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.008891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               obs\n",
       "count  1248.000000\n",
       "mean      0.243541\n",
       "std       1.418613\n",
       "min      -4.120198\n",
       "25%      -0.249621\n",
       "50%       0.000000\n",
       "75%       0.473056\n",
       "max       4.008891"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_df = pd.DataFrame({\n",
    "    \"obs\": td[\"agents\", observation_key].reshape(-1)\n",
    "})\n",
    "obs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnboundedContinuous(\n",
       "    shape=torch.Size([12, 8]),\n",
       "    space=ContinuousBox(\n",
       "        low=Tensor(shape=torch.Size([12, 8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
       "        high=Tensor(shape=torch.Size([12, 8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
       "    device=cpu,\n",
       "    dtype=torch.float32,\n",
       "    domain=continuous)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec[\"agents\", observation_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect Reward Space**\n",
    "\n",
    "It looks like group_reward can be safely ignored. While the reward is -1 on failure, and 0.1 for surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "      <th>group_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.092949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.088070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reward  group_reward\n",
       "count  156.000000         156.0\n",
       "mean     0.092949           0.0\n",
       "std      0.088070           0.0\n",
       "min     -1.000000           0.0\n",
       "25%      0.100000           0.0\n",
       "50%      0.100000           0.0\n",
       "75%      0.100000           0.0\n",
       "max      0.100000           0.0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_df = pd.DataFrame({\n",
    "    \"reward\": td[\"next\", \"agents\", \"reward\"].reshape(-1),\n",
    "    \"group_reward\": td[\"next\", \"agents\", \"group_reward\"].reshape(-1)\n",
    "})\n",
    "reward_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "      <th>group_reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reward  group_reward\n",
       "0       0.1           0.0\n",
       "1       0.1           0.0\n",
       "2       0.1           0.0\n",
       "3       0.1           0.0\n",
       "4       0.1           0.0\n",
       "..      ...           ...\n",
       "151     0.1           0.0\n",
       "152     0.1           0.0\n",
       "153    -1.0           0.0\n",
       "154     0.1           0.0\n",
       "155     0.1           0.0\n",
       "\n",
       "[156 rows x 2 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finalize Environment**\n",
    "The environment is already in a good state, the only thing to do is exclude group_reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(graphics=False):\n",
    "    env = create_base_env(graphics)\n",
    "    env.append_transform(\n",
    "        ExcludeTransform((\"agents\", \"group_reward\"))\n",
    "    )\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.047 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.359209 ms\n",
      "Registered Communicator in Agent.\n",
      "Thread 0x171667000 may have been prematurely finalized\n",
      "Setting up 7 worker threads for Enlighten.\n",
      "Thread 0x170153000 may have been prematurely finalized\n",
      "Memory Statistics:\n",
      "[ALLOC_TEMP_TLS] TLS Allocator\n",
      "  StackAllocators : \n",
      "    [ALLOC_TEMP_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 13172 frames, [1.0 KB-2.0 KB]: 72 frames, [2.0 MB-4.0 MB]: 1 frames\n",
      "      Initial Block Size 4.0 MB\n",
      "      Current Block Size 4.0 MB\n",
      "      Peak Allocated Bytes 2.1 MB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 4]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.PreloadManager]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 78.9 KB\n",
      "      Overflow Count 4\n",
      "    [ALLOC_TEMP_Background Job.worker 3]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 11]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 7]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 6]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 11]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 12]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 2]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 9]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 0]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 4]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 5]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 8]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 10]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 1]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_EnlightenWorker] x 7\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 1]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.5 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 3]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.7 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 5]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 12]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_AssetGarbageCollectorHelper] x 13\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 13]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 15]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 2]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 10]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 7]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_OSX HID Input]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 9]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 0]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 6]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 8]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 14]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.AsyncRead]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 128 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_BatchDeleteObjects]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "[ALLOC_DEFAULT] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 29\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_DEFAULT_MAIN]\n",
      "      Peak usage frame count: [16.0 MB-32.0 MB]: 13245 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 28.9 MB\n",
      "      Peak Large allocation bytes 16.0 MB\n",
      "    [ALLOC_DEFAULT_THREAD]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 1931 frames, [1.0 MB-2.0 MB]: 11314 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.2 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TEMP_JOB_1_FRAME]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_2_FRAMES]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 0\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_4_FRAMES (JobTemp)]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_ASYNC (Background)]\n",
      "  Initial Block Size 1.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_GFX] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_GFX_MAIN]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 13244 frames, [64.0 KB-128.0 KB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 69.7 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_GFX_THREAD]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 13245 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 32.4 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_CACHEOBJECTS] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_CACHEOBJECTS_MAIN]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 13245 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 0.7 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_CACHEOBJECTS_THREAD]\n",
      "      Peak usage frame count: [256.0 KB-0.5 MB]: 13244 frames, [2.0 MB-4.0 MB]: 1 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 2.5 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TYPETREE] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_TYPETREE_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 13245 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 112 B\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_TYPETREE_THREAD]\n",
      "      Peak usage frame count: [1.0 KB-2.0 KB]: 13245 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.9 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "ERROR: Shader UI/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "\u001b[92m2025-09-22 18:05:20,273 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = create_env()\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                VectorSensor_size8: Tensor(shape=torch.Size([12, 12, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                continuous_action: Tensor(shape=torch.Size([12, 12, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([12, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([12, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([12, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([12, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([12, 12]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_mdp(env.rollout(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.048 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.281250 ms\n",
      "Registered Communicator in Agent.\n"
     ]
    }
   ],
   "source": [
    "env = create_env()\n",
    "observation_key = env.observation_keys[0][1]\n",
    "action_key = env.action_key[1]\n",
    "\n",
    "observation_shape = int(env.observation_spec[\"agents\", observation_key].shape[-1])\n",
    "action_shape = int(env.action_spec[\"agents\", action_key].shape[-1])\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "N_BLOCKS = 3\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"hidden_dim\": HIDDEN_DIM,\n",
    "    \"n_blocks\": N_BLOCKS,\n",
    "    \"in_features\": observation_shape,\n",
    "    \"out_features\": action_shape,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 256, 'n_blocks': 3, 'in_features': 8, 'out_features': 2}"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Policy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_policy(config):\n",
    "    config = config.copy()\n",
    "    config[\"out_features\"] *= 2 # Double output dim, for loc and scale\n",
    "    model = MLP(**config)\n",
    "\n",
    "    normal_params_model = nn.Sequential(\n",
    "        model,\n",
    "        NormalParamExtractor()\n",
    "    )\n",
    "    logits_model = TensorDictModule(normal_params_model, in_keys=[(\"agents\", observation_key)], out_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")])\n",
    "    policy = ProbabilisticActor(\n",
    "        module=logits_model,  \n",
    "        distribution_class=TanhNormal,\n",
    "\n",
    "        in_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
    "        out_keys=[(\"agents\", action_key)],\n",
    "\n",
    "        return_log_prob=True,\n",
    "        log_prob_key=(\"agents\", \"log_prob\"),\n",
    "        cache_dist=True,\n",
    "    )\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_value(config):\n",
    "    # Remove out_features from config\n",
    "    config = config.copy()\n",
    "    config[\"out_features\"] = 1\n",
    "\n",
    "    model = MLP(**config)\n",
    "    value = TensorDictModule(model, in_keys=[(\"agents\", observation_key)], out_keys=[(\"agents\", \"state_value\")])\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PPO Loss Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loss_module(policy, value, epsilon, entropy_coef, gamma, lmbda):\n",
    "    loss_module = ClipPPOLoss(\n",
    "        actor_network=policy,\n",
    "        critic_network=value,\n",
    "        clip_epsilon=epsilon,\n",
    "        entropy_coeff=entropy_coef,\n",
    "        # normalize_advantage=True,\n",
    "    )\n",
    "    \n",
    "    loss_module.set_keys(\n",
    "        action=(\"agents\", action_key),\n",
    "        sample_log_prob=(\"agents\", \"log_prob\"),\n",
    "        value=(\"agents\", \"state_value\"),\n",
    "\n",
    "        advantage=(\"agents\", \"advantage\"),\n",
    "        value_target=(\"agents\", \"value_target\"),\n",
    "\n",
    "        reward=(\"agents\", \"reward\"),\n",
    "        done=(\"agents\", \"done\"),\n",
    "        terminated=(\"agents\", \"terminated\"),\n",
    "        # truncated can be left out, PPO uses done/terminated for bootstrapping\n",
    "    )\n",
    "\n",
    "    loss_module.make_value_estimator(ValueEstimators.GAE, gamma=gamma, lmbda=lmbda)\n",
    "\n",
    "    return loss_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                VectorSensor_size8: Tensor(shape=torch.Size([14, 12, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                advantage: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                continuous_action: Tensor(shape=torch.Size([14, 12, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                loc: Tensor(shape=torch.Size([14, 12, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                log_prob: Tensor(shape=torch.Size([14, 12]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                scale: Tensor(shape=torch.Size([14, 12, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state_value: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                value_target: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([14, 12]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([14, 12, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        state_value: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([14, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([14, 12]),\n",
       "                    device=None,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([14]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([14]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy, value = create_policy(MODEL_CONFIG).to(device), create_value(MODEL_CONFIG).to(device)\n",
    "loss_module = make_loss_module(policy, value, epsilon=0.1, entropy_coef=0.01, gamma=0.99, lmbda=0.95).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    td = env.rollout(100, policy=policy)\n",
    "    loss_module.value_estimator(td)\n",
    "data = step_mdp(td)[\"agents\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Loop Params\n",
    "STORAGE_DEVICE = device # Use \"cpu\" to keep dataset in RAM, this is better if you have large datasets, then move only minibatches to VRAM.\n",
    "TIMESTAMPS = 20_000\n",
    "GENERATION_SIZE = 512\n",
    "EPOCHS = 10\n",
    "\n",
    "# GD Params\n",
    "MINIBATCH_SIZE = 32\n",
    "LR = 3e-4\n",
    "MAX_GRAD_NORM = 0.5\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "### RL Params\n",
    "\n",
    "# ENV Params (None)\n",
    "\n",
    "# PPO Params\n",
    "GAMMA = 0.999\n",
    "GAE_LAMBDA = 0.95\n",
    "EPSILON = 0.2\n",
    "ENTROPY_COEF = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINUE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.063 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.345292 ms\n",
      "Registered Communicator in Agent.\n",
      "ERROR: Shader UI/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "Thread 0x16effb000 may have been prematurely finalized\n",
      "Setting up 7 worker threads for Enlighten.\n",
      "Thread 0x16dae7000 may have been prematurely finalized\n",
      "Thread 0x16db73000 may have been prematurely finalized\n",
      "Memory Statistics:\n",
      "[ALLOC_TEMP_TLS] TLS Allocator\n",
      "  StackAllocators : \n",
      "    [ALLOC_TEMP_MAIN]\n",
      "      Peak usage frame count: [2.0 MB-4.0 MB]: 1 frames\n",
      "      Initial Block Size 4.0 MB\n",
      "      Current Block Size 4.0 MB\n",
      "      Peak Allocated Bytes 2.1 MB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 4]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.PreloadManager]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 78.9 KB\n",
      "      Overflow Count 4\n",
      "    [ALLOC_TEMP_Background Job.worker 3]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 11]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 7]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 6]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 11]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 12]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 2]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 9]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 0]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 4]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 5]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 8]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 10]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 1]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_EnlightenWorker] x 7\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 1]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.7 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 3]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 5]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 12]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_AssetGarbageCollectorHelper] x 13\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 13]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 15]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 2]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 440 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 10]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 7]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_OSX HID Input]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 9]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 0]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 6]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 8]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 14]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.AsyncRead]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 128 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_BatchDeleteObjects]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "[ALLOC_DEFAULT] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 29\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_DEFAULT_MAIN]\n",
      "      Peak usage frame count: [16.0 MB-32.0 MB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 28.9 MB\n",
      "      Peak Large allocation bytes 16.0 MB\n",
      "    [ALLOC_DEFAULT_THREAD]\n",
      "      Peak usage frame count: [1.0 MB-2.0 MB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.0 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TEMP_JOB_1_FRAME]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_2_FRAMES]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 0\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_4_FRAMES (JobTemp)]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_ASYNC (Background)]\n",
      "  Initial Block Size 1.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_GFX] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_GFX_MAIN]\n",
      "      Peak usage frame count: [64.0 KB-128.0 KB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 69.7 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_GFX_THREAD]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 32.4 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_CACHEOBJECTS] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_CACHEOBJECTS_MAIN]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 1 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 0.7 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_CACHEOBJECTS_THREAD]\n",
      "      Peak usage frame count: [2.0 MB-4.0 MB]: 1 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 2.5 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TYPETREE] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_TYPETREE_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 1 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 112 B\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_TYPETREE_THREAD]\n",
      "      Peak usage frame count: [1.0 KB-2.0 KB]: 1 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.9 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/3DBall.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/3DBall.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.047 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.274083 ms\n",
      "Registered Communicator in Agent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/collectors/collectors.py:870: UserWarning: total_frames (20000) is not exactly divisible by frames_per_batch (512). This means 480 additional frames will be collected.To silence this message, set the environment variable RL_WARNINGS to False.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Shader UI/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "Thread 0x171dcf000 may have been prematurely finalized\n",
      "Setting up 7 worker threads for Enlighten.\n",
      "Thread 0x17082f000 may have been prematurely finalized\n",
      "Memory Statistics:\n",
      "[ALLOC_TEMP_TLS] TLS Allocator\n",
      "  StackAllocators : \n",
      "    [ALLOC_TEMP_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 6910301 frames, [1.0 KB-2.0 KB]: 37432 frames, [2.0 MB-4.0 MB]: 1 frames\n",
      "      Initial Block Size 4.0 MB\n",
      "      Current Block Size 4.0 MB\n",
      "      Peak Allocated Bytes 2.1 MB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 4]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.PreloadManager]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 78.9 KB\n",
      "      Overflow Count 4\n",
      "    [ALLOC_TEMP_Background Job.worker 3]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 11]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 7]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 6]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 11]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 12]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 2]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 9]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 0]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 4]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 5]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 8]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 10]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 1]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_EnlightenWorker] x 7\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 1]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.5 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 3]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 5]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 12]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_AssetGarbageCollectorHelper] x 13\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 13]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 15]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 2]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0.7 KB\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 10]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 7]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_OSX HID Input]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 9]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 0]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 6]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Job.worker 8]\n",
      "      Initial Block Size 256.0 KB\n",
      "      Current Block Size 256.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Background Job.worker 14]\n",
      "      Initial Block Size 32.0 KB\n",
      "      Current Block Size 32.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_Loading.AsyncRead]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 128 B\n",
      "      Overflow Count 0\n",
      "    [ALLOC_TEMP_BatchDeleteObjects]\n",
      "      Initial Block Size 64.0 KB\n",
      "      Current Block Size 64.0 KB\n",
      "      Peak Allocated Bytes 0 B\n",
      "      Overflow Count 0\n",
      "[ALLOC_DEFAULT] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 29\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_DEFAULT_MAIN]\n",
      "      Peak usage frame count: [16.0 MB-32.0 MB]: 6947734 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 28.9 MB\n",
      "      Peak Large allocation bytes 16.0 MB\n",
      "    [ALLOC_DEFAULT_THREAD]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 1833 frames, [1.0 MB-2.0 MB]: 6945901 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.2 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TEMP_JOB_1_FRAME]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_2_FRAMES]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 0\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_4_FRAMES (JobTemp)]\n",
      "  Initial Block Size 2.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_TEMP_JOB_ASYNC (Background)]\n",
      "  Initial Block Size 1.0 MB\n",
      "  Used Block Count 1\n",
      "  Overflow Count (too large) 0\n",
      "  Overflow Count (full) 0\n",
      "[ALLOC_GFX] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_GFX_MAIN]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 6947733 frames, [64.0 KB-128.0 KB]: 1 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 69.7 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_GFX_THREAD]\n",
      "      Peak usage frame count: [32.0 KB-64.0 KB]: 6947734 frames\n",
      "      Requested Block Size 16.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 32.4 KB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_CACHEOBJECTS] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_CACHEOBJECTS_MAIN]\n",
      "      Peak usage frame count: [0.5 MB-1.0 MB]: 6947734 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 0.7 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_CACHEOBJECTS_THREAD]\n",
      "      Peak usage frame count: [256.0 KB-0.5 MB]: 6947733 frames, [2.0 MB-4.0 MB]: 1 frames\n",
      "      Requested Block Size 4.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 2.5 MB\n",
      "      Peak Large allocation bytes 0 B\n",
      "[ALLOC_TYPETREE] Dual Thread Allocator\n",
      "  Peak main deferred allocation count 0\n",
      "    [ALLOC_BUCKET]\n",
      "      Large Block size 4.0 MB\n",
      "      Used Block count 1\n",
      "      Peak Allocated bytes 1.1 MB\n",
      "    [ALLOC_TYPETREE_MAIN]\n",
      "      Peak usage frame count: [0-1.0 KB]: 6947734 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 112 B\n",
      "      Peak Large allocation bytes 0 B\n",
      "    [ALLOC_TYPETREE_THREAD]\n",
      "      Peak usage frame count: [1.0 KB-2.0 KB]: 6947734 frames\n",
      "      Requested Block Size 2.0 MB\n",
      "      Peak Block count 1\n",
      "      Peak Allocated memory 1.9 KB\n",
      "      Peak Large allocation bytes 0 B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "# Create env\n",
    "env = create_env(graphics=False)\n",
    "\n",
    "# Create Models\n",
    "if not CONTINUE:\n",
    "    policy = create_policy(MODEL_CONFIG).to(device)\n",
    "    value = create_value(MODEL_CONFIG).to(device)\n",
    "\n",
    "# Create Collecter (Iterates through Environment) + Replay Buffer (Data Loader + Storage)\n",
    "collector = SyncDataCollector(create_env, policy, frames_per_batch=GENERATION_SIZE, total_frames=TIMESTAMPS, device=device, storing_device=STORAGE_DEVICE)\n",
    "replay_buffer = ReplayBuffer(storage=LazyTensorStorage(GENERATION_SIZE, device=STORAGE_DEVICE), sampler=SamplerWithoutReplacement(), batch_size=MINIBATCH_SIZE)\n",
    "\n",
    "# Loss + Optimizer\n",
    "loss_module = make_loss_module(policy, value, epsilon=EPSILON, entropy_coef=ENTROPY_COEF, gamma=GAMMA, lmbda=GAE_LAMBDA)\n",
    "optimizer = optim.AdamW(loss_module.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "### TRAINING LOOP\n",
    "for i, tensordict_data in enumerate(collector):\n",
    "    # 1. Compute Advantages and Value Target\n",
    "    with torch.no_grad():\n",
    "        loss_module.value_estimator(tensordict_data)\n",
    "\n",
    "    # 2. Minibatch Gradient Descent Loop\n",
    "    replay_buffer.empty(); replay_buffer.extend(tensordict_data)\n",
    "    for epoch in range(EPOCHS):\n",
    "        for _ in range(GENERATION_SIZE // MINIBATCH_SIZE):\n",
    "            # 3. Optimization Step\n",
    "            batch = replay_buffer.sample(MINIBATCH_SIZE).to(device)\n",
    "            loss_data = loss_module(batch)\n",
    "            loss = loss_data[\"loss_objective\"] + loss_data[\"loss_critic\"] + loss_data[\"loss_entropy\"]\n",
    "            optimizer.zero_grad(); loss.backward()\n",
    "            nn.utils.clip_grad_norm_(loss_module.parameters(), max_norm=MAX_GRAD_NORM)\n",
    "            optimizer.step()\n",
    "\n",
    "    # 4. Log results\n",
    "    dataset = step_mdp(tensordict_data)[\"agents\"]\n",
    "    mean_step_reward = dataset[\"reward\"].mean()\n",
    "    mean_return = dataset[\"value_target\"].mean()\n",
    "    action_std = dataset[action_key].std()\n",
    "    n_done = dataset[\"done\"].sum()\n",
    "    print(f\"PROGRESS: {(i+1)*GENERATION_SIZE}/{TIMESTAMPS}, MEAN RETURN: {mean_return}, MEAN STEP REWARD: {mean_step_reward}, ACTION STD: {action_std}, DONE: {n_done}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n"
     ]
    }
   ],
   "source": [
    "env = create_env(graphics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                VectorSensor_size8: Tensor(shape=torch.Size([23, 12, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                continuous_action: Tensor(shape=torch.Size([23, 12, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([23, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                loc: Tensor(shape=torch.Size([23, 12, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                log_prob: Tensor(shape=torch.Size([23, 12]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                scale: Tensor(shape=torch.Size([23, 12, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([23, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([23, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([23, 12]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        VectorSensor_size8: Tensor(shape=torch.Size([23, 12, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([23, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([23, 12, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([23, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([23, 12, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([23, 12]),\n",
       "                    device=None,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([23]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([23]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    data = env.rollout(100, policy=policy)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
