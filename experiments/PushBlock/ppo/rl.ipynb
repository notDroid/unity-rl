{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PushBlockEnv Reinforcement Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = \"../../../envs/PushBlock\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "### Utility\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "### Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "### Torch RL\n",
    "# Env\n",
    "from torchrl.envs.libs import UnityMLAgentsEnv\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from torchrl.envs.utils import step_mdp, check_env_specs\n",
    "from torchrl.envs import TransformedEnv, Stack, ExcludeTransform, CatTensors\n",
    "\n",
    "# Data Collection\n",
    "from torchrl.collectors import SyncDataCollector, MultiSyncDataCollector\n",
    "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "\n",
    "\n",
    "# Model\n",
    "from model import create_policy, create_value\n",
    "# Train Util\n",
    "from train_util import make_loss_module,  compute_trajectory_metrics, loss_dict, Stopwatch, Logger, Checkpointer, compute_single_trajectory_metrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create Torch Env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unity_env(graphics=False, **kwargs):\n",
    "    try:\n",
    "        env.close()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    env = TransformedEnv(UnityMLAgentsEnv(\n",
    "        file_name=ENV_PATH, worker_id=np.random.randint(10000), \n",
    "        no_graphics=(not graphics), **kwargs,\n",
    "        device=\"cpu\",\n",
    "    ))\n",
    "\n",
    "    return env\n",
    "\n",
    "def batch_agents(env, out_key=\"agents\"):\n",
    "    agent_root_key = env.observation_keys[0][0]\n",
    "    agents = list(env.action_spec[agent_root_key].keys())\n",
    "    \n",
    "    # Create transform\n",
    "    stack = Stack(\n",
    "        in_keys=[(agent_root_key, agent) for agent in agents], \n",
    "        out_key=(out_key,), \n",
    "        in_key_inv=(out_key,), \n",
    "        out_keys_inv=[(agent_root_key, agent) for agent in agents]\n",
    "    )\n",
    "\n",
    "    env.append_transform(stack)\n",
    "    return env\n",
    "\n",
    "def create_base_env(graphics=False, **kwargs):\n",
    "    env = create_unity_env(graphics, **kwargs)\n",
    "\n",
    "    # Batch into Agents Dimension\n",
    "    env = batch_agents(env)\n",
    "\n",
    "    # Concatenate Observation\n",
    "    obs_keys = env.observation_keys\n",
    "    env.append_transform(\n",
    "        CatTensors(in_keys=obs_keys, out_key=(\"agents\", \"observation\"), del_keys=False)\n",
    "    )\n",
    "    # Exclude Group Reward\n",
    "    env.append_transform(\n",
    "        ExcludeTransform((\"agents\", \"group_reward\"))\n",
    "    )\n",
    "    return env\n",
    "\n",
    "def create_env(graphics=False, time_scale = 1, **kwargs):\n",
    "    # Time scale\n",
    "    if time_scale != 1:\n",
    "        engine_config_channel = EngineConfigurationChannel()\n",
    "        env = create_base_env(graphics, **kwargs, side_channels=[engine_config_channel])\n",
    "        engine_config_channel.set_configuration_parameters(time_scale=time_scale)\n",
    "    else:\n",
    "        env = create_base_env(graphics, **kwargs)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect Specs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/PushBlock.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/PushBlock.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/PushBlock.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.050 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Legacy Shaders/Diffuse' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Legacy Shaders/Diffuse shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Legacy Shaders/Diffuse' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'ML-Agents/GridPattern' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader ML-Agents/GridPattern shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'ML-Agents/GridPattern' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.375542 ms\n",
      "Registered Communicator in Agent.\n",
      "ERROR: Shader UI/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "\u001b[92m2025-09-27 20:42:58,057 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n",
      "action_spec: Composite(\n",
      "    agents: Composite(\n",
      "        discrete_action: MultiOneHot(\n",
      "            shape=torch.Size([32, 7]),\n",
      "            space=BoxList(boxes=[CategoricalBox(n=7)]),\n",
      "            device=cpu,\n",
      "            dtype=torch.int32,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([32]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "reward_spec: Composite(\n",
      "    agents: Composite(\n",
      "        reward: UnboundedContinuous(\n",
      "            shape=torch.Size([32, 1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([32, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([32, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([32]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "done_spec: Composite(\n",
      "    agents: Composite(\n",
      "        done: Categorical(\n",
      "            shape=torch.Size([32, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        terminated: Categorical(\n",
      "            shape=torch.Size([32, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        truncated: Categorical(\n",
      "            shape=torch.Size([32, 1]),\n",
      "            space=CategoricalBox(n=2),\n",
      "            device=cpu,\n",
      "            dtype=torch.bool,\n",
      "            domain=discrete),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([32]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n",
      "observation_spec: Composite(\n",
      "    agents: Composite(\n",
      "        StackingSensor_size3_OffsetRayPerceptionSensor: UnboundedContinuous(\n",
      "            shape=torch.Size([32, 105]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([32, 105]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([32, 105]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        StackingSensor_size3_RayPerceptionSensor: UnboundedContinuous(\n",
      "            shape=torch.Size([32, 105]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([32, 105]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([32, 105]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        observation: UnboundedContinuous(\n",
      "            shape=torch.Size([32, 210]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([32, 210]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([32, 210]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cpu,\n",
      "        shape=torch.Size([32]),\n",
      "        data_cls=None),\n",
      "    device=cpu,\n",
      "    shape=torch.Size([]),\n",
      "    data_cls=None)\n"
     ]
    }
   ],
   "source": [
    "def print_specs(env):\n",
    "    print(\"action_spec:\", env.action_spec)\n",
    "    print(\"reward_spec:\", env.reward_spec)\n",
    "    print(\"done_spec:\", env.done_spec)\n",
    "    print(\"observation_spec:\", env.observation_spec)\n",
    "\n",
    "env = create_env(time_scale=20)\n",
    "check_env_specs(env)\n",
    "print_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_key: discrete_action\n",
      "observation_shape: torch.Size([32, 210]), action_shape: torch.Size([32, 7])\n"
     ]
    }
   ],
   "source": [
    "action_key = env.action_key[1]\n",
    "print(f\"action_key: {action_key}\")\n",
    "\n",
    "observation_shape = env.observation_spec[\"agents\", \"observation\"].shape\n",
    "action_shape = env.action_spec[\"agents\", action_key].shape\n",
    "\n",
    "print(f\"observation_shape: {observation_shape}, action_shape: {action_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                StackingSensor_size3_OffsetRayPerceptionSensor: Tensor(shape=torch.Size([10, 32, 105]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                StackingSensor_size3_RayPerceptionSensor: Tensor(shape=torch.Size([10, 32, 105]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                discrete_action: Tensor(shape=torch.Size([10, 32, 7]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([10, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([10, 32, 210]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([10, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([10, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([10, 32]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                agents: TensorDict(\n",
       "                    fields={\n",
       "                        StackingSensor_size3_OffsetRayPerceptionSensor: Tensor(shape=torch.Size([10, 32, 105]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        StackingSensor_size3_RayPerceptionSensor: Tensor(shape=torch.Size([10, 32, 105]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        done: Tensor(shape=torch.Size([10, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        observation: Tensor(shape=torch.Size([10, 32, 210]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        reward: Tensor(shape=torch.Size([10, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        terminated: Tensor(shape=torch.Size([10, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                        truncated: Tensor(shape=torch.Size([10, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "                    batch_size=torch.Size([10, 32]),\n",
       "                    device=cpu,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([10]),\n",
       "            device=cpu,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([10]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = env.rollout(10)\n",
    "td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect Action Space**\n",
    "\n",
    "We have categorical actions: 7 choices (choose one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.350005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            action\n",
       "count  2240.000000\n",
       "mean      0.142857\n",
       "std       0.350005\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_df = pd.DataFrame({\n",
    "    \"action\": td[\"agents\", action_key].reshape(-1)\n",
    "})\n",
    "actions_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect Observation Space**\n",
    "\n",
    "Observations consist of binary features and continuous features scaled to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.366839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.464883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                obs\n",
       "count  67200.000000\n",
       "mean       0.366839\n",
       "std        0.464883\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_df = pd.DataFrame({\n",
    "    \"obs\": td[\"agents\", \"observation\"].reshape(-1)\n",
    "})\n",
    "obs_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect Reward Space**\n",
    "-0.001 for surviving, +1 on success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reward\n",
       "count  320.000\n",
       "mean    -0.001\n",
       "std      0.000\n",
       "min     -0.001\n",
       "25%     -0.001\n",
       "50%     -0.001\n",
       "75%     -0.001\n",
       "max     -0.001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_df = pd.DataFrame({\n",
    "    \"reward\": td[\"next\", \"agents\", \"reward\"].reshape(-1),\n",
    "})\n",
    "reward_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_dim': 256, 'n_blocks': 3, 'in_features': 210, 'out_features': 7}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIDDEN_DIM = 256\n",
    "N_BLOCKS = 3\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"hidden_dim\": HIDDEN_DIM,\n",
    "    \"n_blocks\": N_BLOCKS,\n",
    "    \"in_features\": int(observation_shape[1]),\n",
    "    \"out_features\": int(action_shape[1]),\n",
    "}\n",
    "MODEL_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inspect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        StackingSensor_size3_OffsetRayPerceptionSensor: Tensor(shape=torch.Size([9, 32, 105]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        StackingSensor_size3_RayPerceptionSensor: Tensor(shape=torch.Size([9, 32, 105]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        advantage: Tensor(shape=torch.Size([9, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        discrete_action: Tensor(shape=torch.Size([9, 32, 7]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([9, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        log_prob: Tensor(shape=torch.Size([9, 32]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        logits: Tensor(shape=torch.Size([9, 32, 7]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([9, 32, 210]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([9, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        state_value: Tensor(shape=torch.Size([9, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([9, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        truncated: Tensor(shape=torch.Size([9, 32, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        value_target: Tensor(shape=torch.Size([9, 32, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([9, 32]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy, value = create_policy(MODEL_CONFIG).to(device), create_value(MODEL_CONFIG).to(device)\n",
    "loss_module = make_loss_module(policy, value, epsilon=0.1, entropy_coef=0.01, gamma=0.99, lmbda=0.95).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    td = env.rollout(10, policy=policy, auto_cast_to_device=True).to(device)\n",
    "    loss_module.value_estimator(td)\n",
    "data = step_mdp(td)[\"agents\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return': 0.14822500944137573,\n",
       " 'episode_length': 9.0,\n",
       " 'entropy': 1.80357825756073}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_single_trajectory_metrics(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu workers: 1\n"
     ]
    }
   ],
   "source": [
    "device_type = \"cuda\" if str(device).startswith(\"cuda\") else \"cpu\"\n",
    "amp_dtype   = torch.float16 if device_type == \"cuda\" else torch.float32\n",
    "\n",
    "### Training Loop Params\n",
    "WORKERS = os.cpu_count()\n",
    "print(\"device:\", device, \"workers:\", WORKERS)\n",
    "STORAGE_DEVICE = device\n",
    "GENERATION_SIZE = 1000 * WORKERS # 1000 is the truncation point for the env\n",
    "TIMESTAMPS = GENERATION_SIZE * 50\n",
    "EPOCHS = 5\n",
    "\n",
    "# GD Params\n",
    "MINIBATCH_SIZE = 64\n",
    "LR = 5e-5\n",
    "MAX_GRAD_NORM = 0.5\n",
    "\n",
    "### RL Params\n",
    "\n",
    "# ENV Params\n",
    "TIME_SCALE = 20\n",
    "\n",
    "# PPO Params\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "EPSILON = 0.2\n",
    "ENTROPY_COEF = 1e-5\n",
    "\n",
    "LOG_KEYS = [\n",
    "    \"generation\", \"time\", \"collection_time\", \"train_time\",  # Training Progress Metrics\n",
    "    \"return\", \"episode_length\",                             # Performance Metrics\n",
    "    \"entropy\",                                              # Exploration Metrics\n",
    "    \"policy_loss\", \"kl_approx\", \"clip_fraction\", \"ESS\",     # Policy Metrics\n",
    "    \"value_loss\", \"explained_variance\",                     # Value Metrics\n",
    "]\n",
    "\n",
    "LOG_PATH = 'logs'\n",
    "CKPT_PATH = 'ckpt'\n",
    "MODEL_PATH = 'models'\n",
    "NAME = 'run0'\n",
    "\n",
    "LOG_INTERVAL = 1\n",
    "CHECKPOINT_INTERVAL = 1\n",
    "METRIC_KEY = \"return\"\n",
    "\n",
    "CONTINUE=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(create_env, policy, value, timestamps=TIMESTAMPS):\n",
    "    # Loss + Optimizer\n",
    "    loss_module = make_loss_module(policy, value, epsilon=EPSILON, entropy_coef=ENTROPY_COEF, gamma=GAMMA, lmbda=GAE_LAMBDA)\n",
    "    optimizer = optim.Adam(loss_module.parameters(), lr=LR)\n",
    "    # only need scaler with float16, float32 and bfloat16 have wider exponent ranges.\n",
    "    scaler = torch.amp.GradScaler(enabled=(amp_dtype == torch.float16))\n",
    "\n",
    "    # Logger + Checkpointer\n",
    "    logger = Logger(keys = LOG_KEYS, log_path=LOG_PATH, name=NAME)\n",
    "    checkpointer = Checkpointer(ckpt_path=CKPT_PATH, name=NAME)\n",
    "    \n",
    "\n",
    "    # Continue/Reset\n",
    "    start_generation = 0\n",
    "    if not CONTINUE:\n",
    "        logger.reset()\n",
    "        checkpointer.reset()\n",
    "    else:\n",
    "        checkpoint = checkpointer.load_progress()\n",
    "        if checkpoint:\n",
    "            start_generation = int(checkpoint[\"generation\"])\n",
    "            policy.load_state_dict(checkpoint[\"policy_state_dict\"])\n",
    "            value.load_state_dict(checkpoint[\"value_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            if \"scaler_state_dict\" in checkpoint:\n",
    "                scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "            print(\"CHECKPOINT FOUND, STARTING FROM GENERATION:\", start_generation)\n",
    "        else:\n",
    "            print(\"CHECKPOINT NOT FOUND, STARTING FROM SCRATCH\")\n",
    "\n",
    "    # Watches\n",
    "    short_watch = Stopwatch()\n",
    "    long_watch = Stopwatch()\n",
    "\n",
    "    if WORKERS > 1:\n",
    "        collector = MultiSyncDataCollector([create_env]*WORKERS, policy, \n",
    "            frames_per_batch=GENERATION_SIZE, \n",
    "            total_frames=timestamps - GENERATION_SIZE*start_generation, \n",
    "            env_device=\"cpu\", device=device, storing_device=STORAGE_DEVICE, \n",
    "            update_at_each_batch=True\n",
    "        )\n",
    "    else:\n",
    "        collector = SyncDataCollector(\n",
    "            create_env, policy, \n",
    "            frames_per_batch=GENERATION_SIZE, \n",
    "            total_frames=timestamps - GENERATION_SIZE*start_generation, \n",
    "            env_device=\"cpu\", device=device, storing_device=STORAGE_DEVICE,\n",
    "        )\n",
    "    replay_buffer = ReplayBuffer(storage=LazyTensorStorage(GENERATION_SIZE, device=STORAGE_DEVICE), sampler=SamplerWithoutReplacement(), batch_size=MINIBATCH_SIZE)\n",
    "\n",
    "\n",
    "    ### TRAINING LOOP\n",
    "    short_watch.start(); long_watch.start()\n",
    "    policy.eval(); value.eval()\n",
    "    for i, tensordict_data in enumerate(collector):\n",
    "        # 0. Time collect\n",
    "        collection_time = short_watch.end()\n",
    "        logger.sum({\"collection_time\": collection_time})\n",
    "\n",
    "        # 1. Compute Advantages and Value Target and Metrics\n",
    "        tensordict_data = tensordict_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            loss_module.value_estimator(tensordict_data)\n",
    "            metrics = compute_trajectory_metrics(tensordict_data)\n",
    "        logger.add(metrics)\n",
    "\n",
    "        # 2. Minibatch Gradient Descent Loop\n",
    "        short_watch.start()\n",
    "        policy.train(); value.train()\n",
    "        replay_buffer.empty(); replay_buffer.extend(tensordict_data.reshape(-1))\n",
    "        for epoch in range(EPOCHS):\n",
    "            for j, batch in enumerate(replay_buffer):\n",
    "                # 2.1 Optimization Step\n",
    "                batch = batch.to(device)\n",
    "                with torch.autocast(device_type=device_type, dtype=amp_dtype, enabled=(amp_dtype==torch.float16)):\n",
    "                    loss_data = loss_module(batch)\n",
    "                    loss = loss_data[\"loss_objective\"] + loss_data[\"loss_critic\"] + loss_data[\"loss_entropy\"]\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(loss_module.parameters(), max_norm=MAX_GRAD_NORM)\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                # 2.2 Accumulate Metric\n",
    "                weight = float(batch.batch_size[0])\n",
    "                logger.accumulate(loss_dict(loss_data, weight))\n",
    "        policy.eval(); value.eval()\n",
    "        train_time = short_watch.end()\n",
    "        logger.sum({\"train_time\": train_time})\n",
    "\n",
    "        # 3. Log results\n",
    "        logger.sum({\"generation\": 1})\n",
    "        if (i % LOG_INTERVAL) == 0:\n",
    "            logger.sum({\"time\": long_watch.end()})\n",
    "            long_watch.start()\n",
    "            logger.next(print_row=True)\n",
    "        # 4. Checkpoint model\n",
    "        if (i % CHECKPOINT_INTERVAL) == 0:\n",
    "            gen = int(start_generation + i + 1)\n",
    "            metric = metrics[METRIC_KEY]\n",
    "            checkpointer.save_progress(metric_key=METRIC_KEY,\n",
    "            state_obj={\n",
    "                \"generation\": gen,\n",
    "                \"policy_state_dict\": policy.state_dict(),\n",
    "                \"value_state_dict\": value.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scaler_state_dict\": scaler.state_dict(),\n",
    "                METRIC_KEY: metric,\n",
    "            })\n",
    "\n",
    "        # 5. Start collection time\n",
    "        short_watch.start()\n",
    "\n",
    "    checkpointer.copy_model('latest', MODEL_PATH, ('policy_state_dict', 'value_state_dict'))\n",
    "    return logger.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Mono path[0] = '/Users/walimirza/unity-rl/envs/PushBlock.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/walimirza/unity-rl/envs/PushBlock.app/Contents/MonoBleedingEdge/etc'\n",
      "[Physics::Module] Initialized MultithreadedJobDispatcher with 13 workers.\n",
      "New input system (experimental) initialized\n",
      "Initialize engine version: 2023.2.13f1 (70197a359f36)\n",
      "[Subsystems] Discovering subsystems at path /Users/walimirza/unity-rl/envs/PushBlock.app/Contents/Resources/Data/UnitySubsystems\n",
      "Forcing GfxDevice: Null\n",
      "GfxDevice: creating device client; kGfxThreadingModeNonThreaded\n",
      "NullGfxDevice:\n",
      "    Version:  NULL 1.0 [1.0]\n",
      "    Renderer: Null Device\n",
      "    Vendor:   Unity Technologies\n",
      "Begin MonoManager ReloadAssembly\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Loaded All Assemblies, in  0.051 seconds\n",
      "icall.c:1842:\n",
      "icall.c:1842:\n",
      "- Finished resetting the current domain, in  0.001 seconds\n",
      "ERROR: Shader Sprites/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Sprites/Mask shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "ERROR: Shader Legacy Shaders/VertexLit shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Legacy Shaders/Diffuse' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Legacy Shaders/Diffuse shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Legacy Shaders/Diffuse' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'ML-Agents/GridPattern' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader ML-Agents/GridPattern shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'ML-Agents/GridPattern' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Standard shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Standard' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "ERROR: Shader Autodesk Interactive shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n",
      "WARNING: Shader Unsupported: 'Autodesk Interactive' - All subshaders removed\n",
      "WARNING: Shader Did you use #pragma only_renderers and omit this platform?\n",
      "WARNING: Shader If subshaders removal was intentional, you may have forgotten turning Fallback off?\n",
      "UnloadTime: 0.309708 ms\n",
      "Registered Communicator in Agent.\n",
      "ERROR: Shader UI/Default shader is not supported on this GPU (none of subshaders/fallbacks are suitable)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   generation       time  collection_time  train_time    return  \\\n",
      "0           1  34.294036        28.137577     5.78922 -0.421378   \n",
      "\n",
      "   episode_length   entropy  policy_loss  kl_approx  clip_fraction       ESS  \\\n",
      "0           500.0  1.782504     0.026393   0.010858       0.148075  0.980853   \n",
      "\n",
      "   value_loss  explained_variance  \n",
      "0    0.004929            0.610575  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   generation       time  collection_time  train_time    return  \\\n",
      "1           2  68.053759        55.654487   11.622838  0.037738   \n",
      "\n",
      "   episode_length   entropy  policy_loss  kl_approx  clip_fraction       ESS  \\\n",
      "1       90.909088  1.760716     0.005723   0.013393       0.174652  0.976749   \n",
      "\n",
      "   value_loss  explained_variance  \n",
      "1    0.015734            0.514099  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/mlagents3/lib/python3.10/site-packages/torchrl/envs/libs/unity_mlagents.py:373: DeprecationWarning: In future, it will be an error for 'np.bool' scalars to be interpreted as an index\n",
      "  source[group_name][agent_name][\"truncated\"] = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "policy = create_policy(MODEL_CONFIG).to(device)\n",
    "value = create_value(MODEL_CONFIG).to(device)\n",
    "\n",
    "train(lambda: create_env(time_scale=TIME_SCALE), policy, value, timestamps=TIMESTAMPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
